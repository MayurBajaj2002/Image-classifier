{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How a neural network is trained and built manually and the need to use \n",
    "# pre-trained models\n",
    "\n",
    "This is an example of how a neural network looks like. This is a linear model with 2 hidden layers. We cannot use this manual network in actual classifiers or ,or that matter, any AI or ML application because these will be slow and inaccurate. The most accurate of neural networks have more than 10 hidden layers. If we create this manually, then the number of tensors of weights and biases of each layer we have to keep track of will be so large that each epoch will take more than an hour to run. Even if we were to run this model on GPU it won't be too good in terms of accuracy. Hence, we use the torchvisions.models moduke to use in-built neural networks to get a basic architecture and then modify it according to ur needs. However, the process each in-built neural network works or is trained is not very different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building and training a neural network\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class Classifier(nn.Module): #Classifier is a sub-class of nn.Module\n",
    "    def __init__(self): # Works as a constructor\n",
    "        \n",
    "        super().__init__()         \n",
    "        self.input = nn.Linear(50176, 12544)\n",
    "        self.fc1 = nn.Linear(12544, 3136)\n",
    "        self.fc2 = nn.Linear(3136, 392)\n",
    "        self.output = nn.Linear(392, 102)\n",
    "    \n",
    "    def forward_pass(self, x):\n",
    "        \n",
    "        x = self.input(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.output(x)\n",
    "        x = F.softmax(x, dim = 1)        \n",
    "        return x\n",
    "    \n",
    "network = Classifier() #instantiating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.input.bias.data.fill_(0)\n",
    "network.fc1.bias.data.fill_(0)\n",
    "network.fc2.bias.data.fill_(0)\n",
    "network.output.bias.data.fill_(0)\n",
    "network.input.weight.data.normal_(std=0.01)\n",
    "network.fc1.weight.data.normal_(std=0.01)\n",
    "network.fc2.weight.data.normal_(std=0.01)\n",
    "network.output.weight.data.normal_(std=0.01)\n",
    "epochs = 4\n",
    "optimizer = optim.Adam(network.parameters(), lr = 0.002)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "for e in range(epochs):\n",
    "    for images, labels in dataiter:\n",
    "        images.resize_(images.shape[0], 50176)\n",
    "        \n",
    "        optimizer.zero_grad() #resetting the gradients to preserve computational graph\n",
    "        output = network.forward_pass(images) #computes the output given by the untrained network\n",
    "        loss = loss_function(output, labels.long()) #computes the loss using the mess squared error loss function\n",
    "        loss.backward()\n",
    "        optimizer.step() #updates weights and biases"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
